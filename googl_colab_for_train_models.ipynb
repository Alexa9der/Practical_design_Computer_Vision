{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJTeDlNlGn4h",
        "outputId": "b016875b-6f10-4d90-8c7f-1f51ebc8e82b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Practical_design_Computer_Vision'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (48/48), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 82 (delta 26), reused 38 (delta 18), pack-reused 34\u001b[K\n",
            "Receiving objects: 100% (82/82), 41.54 MiB | 23.87 MiB/s, done.\n",
            "Resolving deltas: 100% (35/35), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Alexa9der/Practical_design_Computer_Vision.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuOdwGiVn9gB",
        "outputId": "e45a2d2e-6aef-49bc-e320-aa115d94c37b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "! cd Practical_design_Computer_Vision\n",
        "! git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Rxj0Uw6fSxN"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! mkdir /content/Practical_design_Computer_Vision/data\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTcdk6oDhUvE"
      },
      "outputs": [],
      "source": [
        "! unzip gtsrb-german-traffic-sign.zip -d /content/Practical_design_Computer_Vision/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-snV2wdxmxrJ"
      },
      "source": [
        "# Working with the project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUfmxfONfUPw"
      },
      "outputs": [],
      "source": [
        "%cd Practical_design_Computer_Vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcyjMCLhfUM_"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OyBnXjrjnkJi"
      },
      "outputs": [],
      "source": [
        "! mkdir /content/Practical_design_Computer_Vision/modelcheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqthyGLEqi49"
      },
      "source": [
        "# Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRFaRfSdfUSj",
        "outputId": "93dc7365-c43f-4983-963a-7b37b9f84838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'Practical_design_Computer_Vision'\n",
            "/content/Practical_design_Computer_Vision\n"
          ]
        }
      ],
      "source": [
        "%cd Practical_design_Computer_Vision\n",
        "from  lib.project_functions import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edit_training_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWBv9DOLH7hy",
        "outputId": "754ebac0-d681-473a-ae76-c280af7d8359"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 43/43 [01:03<00:00,  1.48s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "t8UkawDqDiK4"
      },
      "outputs": [],
      "source": [
        "validation_data_generators()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAvH-OqRmxEe",
        "outputId": "3bdb9c82-9735-445f-9d1b-ecb6ac1387f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 39209 images belonging to 43 classes.\n",
            "Found 7841 images belonging to 43 classes.\n"
          ]
        }
      ],
      "source": [
        "X, v, y = generator(train = True, test = True, generator_batch_size= 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UikcbN6CnRvo",
        "outputId": "7b6a1223-f160-4b7a-9421-59862492c0eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "num_classes = int(pd.read_csv(\"data/Train.csv\", usecols= [\"ClassId\"]).nunique())\n",
        "num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHSN1XJPnUtW",
        "outputId": "9643d75c-0a5d-47e4-ffa3-ffee0ab2bc8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 4.9523 - accuracy: 0.0709 \n",
            "Epoch 1: val_loss improved from inf to 3.61812, saving model to modelcheckpoint/best_model_1.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r154/154 [==============================] - 5007s 32s/step - loss: 4.9523 - accuracy: 0.0709 - val_loss: 3.6181 - val_accuracy: 0.0513\n",
            "Epoch 2/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 3.2082 - accuracy: 0.1313 \n",
            "Epoch 2: val_loss improved from 3.61812 to 3.53951, saving model to modelcheckpoint/best_model_1.h5\n",
            "154/154 [==============================] - 5093s 33s/step - loss: 3.2082 - accuracy: 0.1313 - val_loss: 3.5395 - val_accuracy: 0.0787\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - ETA: 0s - loss: 2.9662 - accuracy: 0.1608 \n",
            "Epoch 3: val_loss improved from 3.53951 to 3.27944, saving model to modelcheckpoint/best_model_1.h5\n",
            "154/154 [==============================] - 5088s 33s/step - loss: 2.9662 - accuracy: 0.1608 - val_loss: 3.2794 - val_accuracy: 0.1009\n",
            "Epoch 4/100\n",
            " 41/154 [======>.......................] - ETA: 58:29 - loss: 2.8821 - accuracy: 0.1764"
          ]
        }
      ],
      "source": [
        "input_tensor = Input(shape=(128, 128, 3), name=\"input\")\n",
        "\n",
        "model1_c1 = Conv2D(32, (3, 3), name=\"model1_c1\")(input_tensor)\n",
        "bn = BatchNormalization()(model1_c1)\n",
        "action = Activation('relu')(bn)\n",
        "\n",
        "model1_c2 = Conv2D(32, (3, 3), activation='relu', name = \"model1_c2\")(action)\n",
        "\n",
        "model1_c3 = Conv2D(64, (3, 3), activation='relu', name = \"model1_c3\")(model1_c2)\n",
        "bn = BatchNormalization()(model1_c3)\n",
        "action = Activation('relu')(bn)\n",
        "\n",
        "model1_p1 = MaxPooling2D((2, 2), name = \"model1_p1\")(action)\n",
        "model1_drop1 = Dropout(0.2)(model1_p1)\n",
        "model1_flat= Flatten()(model1_drop1)\n",
        "\n",
        "model1_d1 = Dense(128, activation='relu', name = \"model1_d1\")(model1_flat)\n",
        "model1_d2 = Dense(256, activation='relu', name = \"model1_d2\")(model1_d1)\n",
        "output1 = Dense(num_classes, activation='softmax', name = \"outputs1\")(model1_d2)\n",
        "\n",
        "model_1 = Model(inputs=input_tensor, outputs=output1 )\n",
        "\n",
        "model_1.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "callback = EarlyStopping(\n",
        "    patience=10,\n",
        "    monitor=\"val_loss\",\n",
        "    restore_best_weights=True,\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=\"modelcheckpoint/best_model_1.h5\",\n",
        "    monitor='val_loss',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='min',\n",
        ")\n",
        "\n",
        "\n",
        "hist = model_1.fit(X, epochs=100, verbose = 1, validation_data = v,\n",
        "                   callbacks=[callback, checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwBrHgTHqwz4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}