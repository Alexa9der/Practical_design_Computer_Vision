{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3cd2ec-5415-49cb-9783-9a2493a42da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  lib.project_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbd224f-7f8e-4eb2-ad3c-839eec9507d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = loading_random_data()\n",
    "for image in data:\n",
    "    image_show(image_preprocessing(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eaa664-9704-4ebd-bda8-46bdd2fb7598",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ec360f-d4bc-452c-aa21-4630811c96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_images_by_name(path_to_Train = \"data\\Train\"):\n",
    "\n",
    "    for folder in tqdm(os.listdir(path_to_Train)):\n",
    "        folder_path = os.path.join(path_to_Train, folder)\n",
    "\n",
    "        for image in os.listdir(folder_path):\n",
    "            parts = image.split(\"_\")\n",
    "\n",
    "            if len(parts) > 3:\n",
    "                image_path = os.path.join(folder_path, image)\n",
    "                os.remove(image_path)\n",
    "\n",
    "remove_duplicate_images_by_name(path_to_Train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ab21d3-e13d-4c04-b490-bd718709ea29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd54c9ac-982e-4382-9176-e3add66d3868",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# imega transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d37d8a6-6563-4e02-a117-e5acb764b176",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def edit_training_data( path_to_Train=\"data\\Train\", path_to_edited_data =\"data\\edited_training_data\"):\n",
    "\n",
    "    name_folders = os.listdir(path_to_Train)\n",
    "    os.makedirs(path_to_edited_data, exist_ok=True)\n",
    "    \n",
    "    for name_folder in tqdm(name_folders):\n",
    "        path_to_train_data = os.path.join(path_to_Train, name_folder)\n",
    "        path_to_new_data = os.path.join(path_to_edited_data, name_folder)\n",
    "    \n",
    "        os.makedirs(path_to_new_data, exist_ok=True)\n",
    "        \n",
    "        path_images = os.listdir(path_to_train_data)\n",
    "    \n",
    "        for image in path_images:\n",
    "            train_path = os.path.join(path_to_train_data, image)\n",
    "            new_data_path = os.path.join(path_to_new_data, image)\n",
    "            \n",
    "            if not os.path.exists(new_data_path):\n",
    "                img = cv.imread(train_path)\n",
    "                \n",
    "                if img is not None:\n",
    "                    preprocessed_img = image_preprocessing(img)\n",
    "                    cv.imwrite(new_data_path, preprocessed_img) \n",
    "                \n",
    "    \n",
    "edit_training_data()       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1939a0f3-5cb1-443f-a8c4-5686c32240db",
   "metadata": {},
   "source": [
    "# Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e6f78-b247-4ce7-8da6-e19e837fa00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_batch_size = 32\n",
    "generator_image_size = (128, 128)\n",
    "\n",
    "# Создайте экземпляр ImageDataGenerator\n",
    "image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Масштабирование значений пикселей в диапазон [0, 1]\n",
    "    preprocessing_function= image_preprocessing, # Пользовательская функция предобработки\n",
    "    rotation_range=40,      # Случайное вращение изображения на угол до 40 градусов\n",
    "    width_shift_range=0.2,  # Случайное смещение изображения по горизонтали на 20% от ширины\n",
    "    height_shift_range=0.2, # Случайное смещение изображения по вертикали на 20% от высоты\n",
    "    shear_range=0.2,        # Случайное сдвигание изображения (изогнутость)\n",
    "    zoom_range=0.2,         # Случайное увеличение масштаба изображения\n",
    "    horizontal_flip=True,   # Случайное горизонтальное отражение\n",
    "    fill_mode='nearest'     # Заполнение пикселей после трансформаций\n",
    ")\n",
    "\n",
    "train_data_generator = image_generator.flow_from_directory(\n",
    "    'data/Train',\n",
    "    target_size=generator_image_size,\n",
    "    batch_size=generator_batch_size,\n",
    "    class_mode='categorical'  # Если у вас несколько классов\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d3c1b6-34ea-49ae-a419-1bac96f61037",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_batch = next(train_data_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90dddc-d783-45e2-af34-8812a2ce90ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# image_show(data_from_batch[0][31]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a25597-f795-441f-960e-4686a00f1e82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba41f6a-30f8-470b-ba73-7019fef69a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data_generators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c310b36-e578-4ae6-8ff8-67d5d89d149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_image_generator = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  \n",
    "    preprocessing_function= image_preprocessing, \n",
    "    rotation_range=40,      \n",
    "    width_shift_range=0.2,  \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.2,        \n",
    "    zoom_range=0.2,         \n",
    "    horizontal_flip=True,   \n",
    "    fill_mode='nearest'     \n",
    ")\n",
    "\n",
    "validation_data_generator = validation_image_generator.flow_from_directory(\n",
    "    'data/Validation',\n",
    "    target_size=generator_image_size,\n",
    "    batch_size=generator_batch_size,\n",
    "    class_mode='categorical'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd445125-0c32-40de-926a-ac0ea6f068d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ededf2-0f39-4646-b19e-885fd6fb73a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Укажите путь к папке, из которой вы хотите удалить фотографии\n",
    "folder_path = 'data/Test'\n",
    "\n",
    "# Получите список всех файлов в папке\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "# Пройдитесь по списку файлов и удалите файлы с именем \"00000_1\"\n",
    "for file_name in files:\n",
    "    if \"_\" in  file_name :  # Замените '00000_1.jpg' на желаемое имя файла\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        os.remove(file_path)\n",
    "        print(f'File {file_name} has been deleted.')\n",
    "\n",
    "print('Removal is complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6759123b-6308-46cd-8d21-6ae8deb2f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_generator():\n",
    "    test_data_dir = 'data/Test'\n",
    "    test_data_classes = pd.read_csv(\"data/Test.csv\", usecols= [\"ClassId\",\"Path\"])\n",
    "    test_image_files = os.listdir(test_data_dir)\n",
    "   \n",
    "    for image_file in test_image_files:\n",
    "        image_path = os.path.join(test_data_dir, image_file)\n",
    "        image = cv.imread(image_path)  # Загрузка изображения с использованием OpenCV\n",
    "        # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Преобразование цветового пространства\n",
    "        image = cv.resize(image, generator_image_size)  # Изменение размера изображения\n",
    "        image = image_preprocessing(image)  # Применение пользовательской предобработки\n",
    "        \n",
    "        class_label = int(test_data_classes.loc[image_file == test_data_classes[\"Path\"].str.split(\"/\").str.get(1), \"ClassId\"])\n",
    "        \n",
    "        yield image, (class_label)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_generator(\n",
    "     test_data_generator,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=(*generator_image_size,3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(), dtype=tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d64152-eca3-4670-868b-ef67640b2712",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = test_ds.batch(generator_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54cddb4-51a0-4a18-abe8-411df9a1e77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in test_ds.take(1):  # Взять первый батч из датасета\n",
    "    print(\"Images shape:\", images.shape) # Форма батча изображений\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2b650c-e3c1-4e98-809a-52ce0125444a",
   "metadata": {},
   "source": [
    "data generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bae9f2-5afa-42a1-beb4-6423c6318b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(train:bool, test:bool):\n",
    "\n",
    "    generator_batch_size = 32\n",
    "    generator_image_size = (128, 128)\n",
    "    \n",
    "    # Create an instance of ImageDataGenerator for training data\n",
    "    image_generator = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,  # Scale pixel values to the range [0, 1]\n",
    "        preprocessing_function= image_preprocessing if image_preprocessing else None,  # Custom preprocessing function\n",
    "        rotation_range=40,      # Random rotation up to 40 degrees\n",
    "        width_shift_range=0.2,  # Random horizontal shift of 20% of the width\n",
    "        height_shift_range=0.2, # Random vertical shift of 20% of the height\n",
    "        shear_range=0.2,        # Random shear transformation\n",
    "        zoom_range=0.2,         # Random zoom\n",
    "        horizontal_flip=True,   # Random horizontal flip\n",
    "        fill_mode='nearest'     # Fill mode after transformations\n",
    "    )\n",
    "    \n",
    "    # Create a data generator for training data\n",
    "    train_data_generator = image_generator.flow_from_directory(\n",
    "        'data/Train',\n",
    "        target_size=generator_image_size,\n",
    "        batch_size=generator_batch_size,\n",
    "        class_mode='categorical'  # For multi-class classification\n",
    "    )\n",
    "\n",
    "    validation_image_generator = ImageDataGenerator(\n",
    "        rescale=1.0/255.0,  \n",
    "        preprocessing_function= image_preprocessing if image_preprocessing else None, # image_preprocessing, \n",
    "        rotation_range=40,      \n",
    "        width_shift_range=0.2,  \n",
    "        height_shift_range=0.2, \n",
    "        shear_range=0.2,        \n",
    "        zoom_range=0.2,         \n",
    "        horizontal_flip=True,   \n",
    "        fill_mode='nearest'     \n",
    "    )\n",
    "    \n",
    "    validation_data_generator = validation_image_generator.flow_from_directory(\n",
    "        'data/Validation',\n",
    "        target_size=generator_image_size,\n",
    "        batch_size=generator_batch_size,\n",
    "        class_mode='categorical'  \n",
    "    )\n",
    "\n",
    "    def test_data_generator():\n",
    "        test_data_dir = 'data/Test'\n",
    "        test_data_classes = pd.read_csv(\"data/Test.csv\", usecols=[\"ClassId\", \"Path\"])\n",
    "        test_image_files = os.listdir(test_data_dir)\n",
    "\n",
    "        for image_file in test_image_files:\n",
    "            image_path = os.path.join(test_data_dir, image_file)\n",
    "            image = cv.imread(image_path)  # Load the image using OpenCV\n",
    "            image = cv.resize(image, generator_image_size)  # Resize the image\n",
    "            image = image_preprocessing(image)  # Apply custom preprocessing\n",
    "\n",
    "            class_label = int(test_data_classes.loc[image_file == test_data_classes[\"Path\"].str.split(\"/\").str.get(1), \"ClassId\"])\n",
    "\n",
    "            yield image, class_label\n",
    "            \n",
    "    # Create a tf.data.Dataset for testing data\n",
    "    test_dg = tf.data.Dataset.from_generator(\n",
    "        test_data_generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(*generator_image_size, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32)\n",
    "        )\n",
    "    )\n",
    "    test_dg = test_dg.batch(generator_batch_size)\n",
    "\n",
    "    if train and test:\n",
    "        return train_data_generator, validation_data_generator,  test_dg\n",
    "    elif train:\n",
    "        return train_data_generator, validation_image_generator\n",
    "    elif test:\n",
    "        return test_dg\n",
    "\n",
    "\n",
    "    \n",
    "x, v, y =  generator(train=True, test= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5290b4b3-f2f5-466c-8d45-cc114b6b3b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac58b5d-dd2b-43e6-a677-86061ef2dc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_from_batch = next(x)\n",
    "image_show(data_from_batch[0][31]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a44b3cc-fafc-48b5-b9cd-f65e13096de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in y.take(1):  # Взять первый батч из датасета\n",
    "    print(\"Images shape:\", images.shape) # Форма батча изображений\n",
    "    plt.imshow(images[0])\n",
    "    plt.show()\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d102c5-3e15-4396-8d76-4830612e81d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030d19a4-651e-44db-bae8-3bb384f9114d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e958a-a99f-48da-abca-8d7f5ef9f0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fc75b6-d4b5-4e70-85b9-31e012e50f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb3b1d9-15f5-4562-b54c-d52a05203784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9520ea0-99c7-46c8-b4f5-a95c64638ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2ea44-c6b1-4ca8-ba91-6f790316201f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4b23bc-cf10-4519-ae55-883f7c592c2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f343c750-958f-4899-9c4c-30362273b673",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ea5d39-765b-4e0d-9483-9f23123d8df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dce8963-cac1-4c56-9865-edf0e2dbd16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07466a6-2acd-41c8-914f-de4b5df34b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e551726-7e71-4ac3-849c-48bb9a5e4dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad232712-f8d1-4092-824b-adba9eb874dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317e9a01-4ad8-4665-9d90-acb3acf9e75f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5871a8ec-5584-4687-a786-bef557ae4ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8cc6ae-83ae-4fd9-80a0-70ddd054c4e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd30e60f-b777-4048-9d23-85a0217af9f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab876ba2-1ff7-4927-9f54-230a04b80787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d56ba28-661b-42d1-875a-0fecd8c018cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e06cc3d-00dd-4bf0-b553-b56a3a17d511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978955c2-ce89-47ef-84a1-2b3cdb337a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1403e66f-3086-4255-987e-94a3e070d461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329511b7-9a29-42bf-be2e-d4bae6b414ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d1946-947d-46b2-8f7f-1d649063710d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6440879-b0de-4cbb-90a0-d4981a8d2b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae69e53-7fee-404f-9403-14ba458deb7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ac5ce-4b8c-489f-8079-8dfd12809e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e161b6-c9fe-4f87-85e7-88ae60223a2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc238c9d-d9a4-4ea8-83ff-2ee76dff819a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d4739c-b645-4de7-8cfa-e30a5dd95b16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcd4dd1-876d-4dd9-b54a-6d3601d5d8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fbdf12-6cf7-4153-90e0-fe3caa6306d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
