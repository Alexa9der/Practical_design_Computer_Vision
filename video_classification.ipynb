{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3b3ba-b802-470e-8b3c-b2a0aba3d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  lib.project_functions import * "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55945c3-26e6-45fe-bafe-437faa4eb18a",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10794103-0eef-48c8-b222-272e430a0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_generator(\n",
    "     train_video_data_generation,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
    "train_ds = train_ds.shuffle(100)\n",
    "train_ds = train_ds.batch(32)\n",
    "\n",
    "val_ds = tf.data.Dataset.from_generator(\n",
    "     validation_video_data_generation,\n",
    "     output_signature=(\n",
    "         tf.TensorSpec(shape=( None, 224, 224, 3), dtype=tf.float32),\n",
    "         tf.TensorSpec(shape=(1,), dtype=tf.int32)))\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4c9fe5-272a-4909-b359-990c42fd4954",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator = iter(train_ds)\n",
    "val_iterator = iter(val_ds)\n",
    "\n",
    "print(next(train_iterator)[0].shape, len(next(train_iterator)[1]))\n",
    "print(next(val_iterator)[0].shape, len(next(val_iterator)[1]))\n",
    "# (batch_size, time_steps, height, width, channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111757fe-e167-4918-a505-dfe83603369f",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf03e40-e540-4b91-bf77-f3e3f9597138",
   "metadata": {},
   "outputs": [],
   "source": [
    "convnext_tiny  = tf.keras.applications.convnext.ConvNeXtTiny(\n",
    "                    model_name='convnext_tiny',\n",
    "                    include_top=False,\n",
    "                    include_preprocessing=True,\n",
    "                    weights='imagenet',\n",
    "                    input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce6d58e-8ef6-455d-b219-4a46173d97f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convnext_tiny .summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563cbfb1-dd4a-49b3-9bcd-6e1022c5c3df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_distributed_layer = tf.keras.layers.TimeDistributed(convnext_tiny)\n",
    "\n",
    "inputs = tf.keras.Input(shape=( None, 224, 224, 3))\n",
    "\n",
    "\n",
    "\n",
    "time_distributed_output = time_distributed_layer(inputs)\n",
    "print(\"Shape of time_distributed_output:\", time_distributed_output.shape)\n",
    "\n",
    "flatten = layers.TimeDistributed(layers.Flatten())(time_distributed_output)\n",
    "print(\"Shape of flatten:\", flatten.shape)\n",
    "\n",
    "\n",
    "gru = keras.layers.GRU(128, activation='tanh')(flatten)\n",
    "dance = layers.Dense(64, activation=\"relu\")(gru)\n",
    "print(\"Shape of dance:\", dance.shape)\n",
    "\n",
    "outputs = layers.Dense(5, activation=\"softmax\")(dance)\n",
    "print(\"Shape of outputs:\", outputs.shape)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "callback = EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor=\"val_loss\",\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001\n",
    ")\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath = \"modelcheckpoint/video_best_model_1.h5\",  \n",
    "    monitor='val_loss', \n",
    "    verbose=1,  \n",
    "    save_best_only=True,  \n",
    "    mode='min'  \n",
    ")\n",
    "\n",
    "\n",
    "num_train_samples = sum(1 for _ in train_video_data_generation())\n",
    "steps_per_epoch = round(num_train_samples / 32)\n",
    "\n",
    "\n",
    "hist = model.fit(train_ds, epochs=50, validation_data=val_ds, verbose=1,\n",
    "          callbacks=[callback, checkpoint] , steps_per_epoch=steps_per_epoch) \n",
    "\n",
    "\n",
    "# ValueError: When providing an infinite dataset, you must specify the number of steps to run (if you did not intend to create an infinite dataset, make sure to not call `repeat()` on the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d0cfc0-717e-4e43-a706-57ee523dff17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelcheckpoint/video_model.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8bca39-0e92-4013-97b6-155fce4ef946",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model(\"modelcheckpoint/best_model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dabe3c-0c14-4953-9bdd-914cd450c17e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840494b-8240-42ab-8bd3-9f2741a4d696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfad944-49b9-4c07-a38a-2869ae5dca9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7942d2-979d-417d-a08a-680cfd665dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71740835-3fc7-4ae6-ba02-2e6c4245ab19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135bedb2-9439-4688-8eec-3994889e0667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0812184-b590-4253-98ec-e907310a065e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058accea-dad8-445e-8f2e-b661edbeed01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f8d125-7dca-4d08-a998-dc16d86af3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
